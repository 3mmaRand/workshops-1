---
title: "Big Data with Arrow in R"
author: "Nic Crane + Steph Hazlitt"
date: "2023-09-17"
length: "B-1-day"
description: "1-day workshop"
day-one: "X"
day-two: " "
languages:
  - R
tags:
  - big data
---


# Description

Data analysis pipelines with larger-than-memory data are becoming more and more commonplace. In this workshop you will learn how to use Apache Arrow, a multi-language toolbox for working with larger-than-memory tabular data, to create seamless "big" data analysis pipelines with R. 
  
The workshop will focus on using the the arrow R package---a mature R interface to Apache Arrow--- to process larger-than-memory files and multi-file data sets with arrow using familiar dplyr syntax.  You'll learn to create and use interoperable data file formats like Parquet for efficient data storage and access, with data stored both on disk and in the cloud, and also how to exercise fine control over data types to avoid common large data pipeline problems. This workshop will provide a foundation for using arrow, giving you access to a powerful suite of tools for performant analysis of larger-than-memory data in R.


# Audience

This course is for you if you:

-   want to learn how to work with tabular data that is too large to fit in memory using existing R and tidyverse syntax implemented in Arrow

-   want to learn about Parquet and other file formats that are powerful alternatives to CSV files

-   want to learn how to engineer your tabular data storage for more performant access and analysis with Apache Arrow


# Instructors

**Nic Crane** is a software engineer with a background in data science, and has a lot of enthusiasm for open source and learning and teaching all things R.  Nic is part of the core team who maintain the Arrow R package.

**Steph Hazlitt** is a data scientist, researcher and R enthusiast. She earned a PhD in ecological genetics from the University of Queensland, and since then has spent the better part of her career wrangling data with R and supporting people and teams in learning, creating and sharing data science-related products and open source software.
